{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T10:34:24.342495Z","iopub.status.busy":"2023-05-25T10:34:24.342127Z","iopub.status.idle":"2023-05-25T10:34:24.352400Z","shell.execute_reply":"2023-05-25T10:34:24.351497Z","shell.execute_reply.started":"2023-05-25T10:34:24.342459Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","from torchvision.models import vgg19\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import warnings\n","random.seed(42)\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T10:34:41.315949Z","iopub.status.busy":"2023-05-25T10:34:41.315533Z","iopub.status.idle":"2023-05-25T10:34:41.349922Z","shell.execute_reply":"2023-05-25T10:34:41.348706Z","shell.execute_reply.started":"2023-05-25T10:34:41.315916Z"},"trusted":true},"outputs":[],"source":["class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractor, self).__init__()\n","        vgg19_model = vgg19(pretrained=True)\n","        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n","\n","    def forward(self, img):\n","        return self.feature_extractor(img)\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","        self.conv_block = nn.Sequential(\n","            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(in_features, 0.8),\n","            nn.PReLU(),\n","            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(in_features, 0.8),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n","        super(GeneratorResNet, self).__init__()\n","\n","        # First layer\n","        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU())\n","\n","        # Residual blocks\n","        res_blocks = []\n","        for _ in range(n_residual_blocks):\n","            res_blocks.append(ResidualBlock(64))\n","        self.res_blocks = nn.Sequential(*res_blocks)\n","\n","        # Second conv layer post residual blocks\n","        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8))\n","\n","        # Upsampling layers\n","        upsampling = []\n","        for out_features in range(2):\n","            upsampling += [\n","                # nn.Upsample(scale_factor=2),\n","                nn.Conv2d(64, 256, 3, 1, 1),\n","                nn.BatchNorm2d(256),\n","                nn.PixelShuffle(upscale_factor=2),\n","                nn.PReLU(),\n","            ]\n","        self.upsampling = nn.Sequential(*upsampling)\n","\n","        # Final output layer\n","        self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n","\n","    def forward(self, x):\n","        out1 = self.conv1(x)\n","        out = self.res_blocks(out1)\n","        out2 = self.conv2(out)\n","        out = torch.add(out1, out2)\n","        out = self.upsampling(out)\n","        out = self.conv3(out)\n","        return out\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Discriminator, self).__init__()\n","\n","        self.input_shape = input_shape\n","        in_channels, in_height, in_width = self.input_shape\n","        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n","        self.output_shape = (1, patch_h, patch_w)\n","\n","        def discriminator_block(in_filters, out_filters, first_block=False):\n","            layers = []\n","            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n","            if not first_block:\n","                layers.append(nn.BatchNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n","            layers.append(nn.BatchNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        layers = []\n","        in_filters = in_channels\n","        for i, out_filters in enumerate([64, 128, 256, 512]):\n","            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n","            in_filters = out_filters\n","\n","        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n","\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, img):\n","        return self.model(img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalization parameters for pre-trained PyTorch models\n","mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","cuda = torch.cuda.is_available()\n","hr_height = 256"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-24T14:30:52.531339Z","iopub.status.busy":"2023-05-24T14:30:52.531052Z","iopub.status.idle":"2023-05-24T14:30:52.537626Z","shell.execute_reply":"2023-05-24T14:30:52.536741Z","shell.execute_reply.started":"2023-05-24T14:30:52.531310Z"},"trusted":true},"outputs":[],"source":["cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-25T10:53:34.848602Z","iopub.status.busy":"2023-05-25T10:53:34.848197Z","iopub.status.idle":"2023-05-25T10:53:38.094994Z","shell.execute_reply":"2023-05-25T10:53:38.093877Z","shell.execute_reply.started":"2023-05-25T10:53:34.848563Z"},"trusted":true},"outputs":[],"source":["# Load Model Check Point and pridict the image\n","\n","generator = GeneratorResNet()\n","generator.load_state_dict(torch.load(\"saved_models/generator.pth\"))\n","generator.eval()\n","\n","# Prepare the single image for testing\n","# image_path = \"test_images/test_image.jpg\"  # Replace with the path to your image\n","image_path = \"test_images/test_image.jpg\"  # Replace with the path to your image\n","original_image = Image.open(image_path)\n","width, height = original_image.size   # Get dimensions\n","new_width,new_height,offset = 256,256,256*2\n","left = (width - new_width + offset)/2\n","top = (height - new_height + offset)/2\n","right = (width + new_width + offset)/2\n","bottom = (height + new_height + offset)/2\n","\n","# Crop the center of the image\n","image = original_image.crop((left, top, right, bottom))\n","\n","transform = transforms.Compose([\n","    transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","input_image = transform(image).unsqueeze(0)\n","if cuda:\n","    input_image = input_image\n","\n","# Generate high-resolution output\n","with torch.no_grad():\n","    output_image = generator(input_image)\n","# Convert the generated output to a NumPy array and transpose it\n","output_image = output_image.squeeze(0).cpu().numpy().transpose((1, 2, 0))\n","output_image = (output_image + 1) / 2.0  # Unnormalize the image\n","output_image = Image.fromarray((output_image * 255).astype(np.uint8))\n","transform = transforms.Compose([\n","    transforms.Resize((hr_height//2, hr_height//2), Image.BICUBIC),\n","])\n","image = transform(image)\n","transform = transforms.Compose([\n","    transforms.Resize((height, height), Image.BICUBIC),\n","])\n","image = transform(image)\n","output_image = transform(output_image)\n","# image.show()\n","# Display the original low-resolution image and the generated high-resolution image\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","axes[0].imshow(original_image)\n","axes[0].set_title(f\"Original Image\\n Image Resolution : {original_image.size}\")\n","axes[1].imshow(image)\n","axes[1].set_title(f\"Low-Resolution Image\\n Image Resolution : {image.size}\")\n","axes[2].imshow(output_image)\n","axes[2].set_title(f\"Generated High-Resolution Image\\n Image Resolution : {output_image.size}\")\n","plt.show()\n","\n","original_image.show(title=\"Original Image\")\n","image.show(title=\"Low-Resolution Image\")\n","output_image.show(title=\"Generated High-Resolution Image\")\n","\n","# output_image.save(\"output_images/high_res_generated.png\")\n","# image.save(\"output_images/low_res_input.png\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
